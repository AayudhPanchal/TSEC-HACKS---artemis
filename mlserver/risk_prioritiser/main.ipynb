{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./forest_risks_dataset.csv')\n",
    "\n",
    "X = df['Description']  \n",
    "y = df['Priority']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "joblib.dump(label_encoder, 'models/label_encoder.pkl')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=41, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/vectorizer.pkl']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "joblib.dump(vectorizer, 'models/vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logreg = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],  # These solvers support both L1 and L2 regularization\n",
    "    'max_iter': [100, 200, 300, 500]\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [3, 4, 5],  # Relevant for polynomial kernel\n",
    "    'coef0': [0, 0.1, 1]  # Relevant for polynomial and sigmoid kernels\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
    "    'bootstrap': [True, False]  # Whether to use bootstrap samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "800 fits failed out of a total of 1600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1203, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "38 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "137 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "98 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.40275862 0.46758621 0.55643678 0.50183908        nan        nan\n",
      "        nan        nan 0.40275862 0.46091954 0.55643678 0.50873563\n",
      "        nan        nan        nan        nan 0.40275862 0.42275862\n",
      " 0.55643678 0.51873563        nan        nan        nan        nan\n",
      " 0.40275862 0.4508046  0.55643678 0.50873563        nan        nan\n",
      "        nan        nan 0.47448276 0.47448276 0.72390805 0.73747126\n",
      "        nan        nan        nan        nan 0.47448276 0.47448276\n",
      " 0.72390805 0.73747126        nan        nan        nan        nan\n",
      " 0.47448276 0.47448276 0.72390805 0.73747126        nan        nan\n",
      "        nan        nan 0.47448276 0.47448276 0.72390805 0.73747126\n",
      "        nan        nan        nan        nan 0.79218391 0.80574713\n",
      " 0.84310345 0.88034483        nan        nan        nan        nan\n",
      " 0.79218391 0.79896552 0.84310345 0.88034483        nan        nan\n",
      "        nan        nan 0.79218391 0.79551724 0.84310345 0.88034483\n",
      "        nan        nan        nan        nan 0.79218391 0.79206897\n",
      " 0.84310345 0.88034483        nan        nan        nan        nan\n",
      " 0.93137931 0.93149425 0.9145977  0.91793103        nan        nan\n",
      "        nan        nan 0.93137931 0.93137931 0.9145977  0.91793103\n",
      "        nan        nan        nan        nan 0.93137931 0.9245977\n",
      " 0.9145977  0.91793103        nan        nan        nan        nan\n",
      " 0.93137931 0.92114943 0.9145977  0.91793103        nan        nan\n",
      "        nan        nan 0.92793103 0.94862069 0.9383908  0.93862069\n",
      "        nan        nan        nan        nan 0.93137931 0.94862069\n",
      " 0.9383908  0.94195402        nan        nan        nan        nan\n",
      " 0.93137931 0.94862069 0.9383908  0.93850575        nan        nan\n",
      "        nan        nan 0.92793103 0.94862069 0.9383908  0.93517241\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\aayud\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 360 candidates, totalling 3600 fits\n",
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "gsLogisticModel = GridSearchCV(logistic_model, param_grid_logreg, cv=10, verbose=1, n_jobs=-1)\n",
    "gsLogisticModel.fit(X_train_vec, y_train)\n",
    "\n",
    "svm_model = SVC()\n",
    "gsSvmModel = GridSearchCV(svm_model, param_grid_svm, cv=10, verbose=1, n_jobs=-1)\n",
    "gsSvmModel.fit(X_train_vec, y_train)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "gsRfModel = GridSearchCV(rf_model, param_grid_rf, cv=10, verbose=1, n_jobs=-1)\n",
    "gsRfModel.fit(X_train_vec, y_train)\n",
    "\n",
    "best_logistic_model = gsLogisticModel.best_estimator_\n",
    "best_svm_model = gsSvmModel.best_estimator_\n",
    "best_rf_model = gsRfModel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.59%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.97      1.00      0.98        30\n",
      "         Low       1.00      0.56      0.71         9\n",
      "      Medium       0.92      1.00      0.96        35\n",
      "\n",
      "    accuracy                           0.95        74\n",
      "   macro avg       0.96      0.85      0.89        74\n",
      "weighted avg       0.95      0.95      0.94        74\n",
      "\n",
      "SVM Accuracy: 93.24%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.97      1.00      0.98        30\n",
      "         Low       1.00      0.44      0.62         9\n",
      "      Medium       0.90      1.00      0.95        35\n",
      "\n",
      "    accuracy                           0.93        74\n",
      "   macro avg       0.96      0.81      0.85        74\n",
      "weighted avg       0.94      0.93      0.92        74\n",
      "\n",
      "Random Forest Accuracy: 91.89%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.97      0.97      0.97        30\n",
      "         Low       1.00      0.44      0.62         9\n",
      "      Medium       0.88      1.00      0.93        35\n",
      "\n",
      "    accuracy                           0.92        74\n",
      "   macro avg       0.95      0.80      0.84        74\n",
      "weighted avg       0.93      0.92      0.91        74\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/rf_model.pkl']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logistic = best_logistic_model.predict(X_test_vec)\n",
    "y_pred_svm = best_svm_model.predict(X_test_vec)\n",
    "y_pred_rf = best_rf_model.predict(X_test_vec)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_logistic, target_names=label_encoder.classes_))\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n",
    "\n",
    "joblib.dump(best_logistic_model, 'models/logreg_model.pkl')\n",
    "joblib.dump(best_svm_model, 'models/svm_model.pkl')\n",
    "joblib.dump(best_rf_model, 'models/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Priority\n",
       "Medium    174\n",
       "High      148\n",
       "Low        45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: A massive wildfire is approaching a nearby village, causing panic.\n",
      "🔹 Logistic Regression Prediction: High\n",
      "🔹 SVM Prediction: High\n",
      "🔹 Random Forest Prediction: High\n",
      "\n",
      "Text: A group of armed poachers was seen near the protected tiger reserve.\n",
      "🔹 Logistic Regression Prediction: Low\n",
      "🔹 SVM Prediction: Low\n",
      "🔹 Random Forest Prediction: Medium\n",
      "\n",
      "Text: A rare medicinal plant species is being stolen from the forest.\n",
      "🔹 Logistic Regression Prediction: High\n",
      "🔹 SVM Prediction: High\n",
      "🔹 Random Forest Prediction: Medium\n",
      "\n",
      "Text: A tourist was injured while hiking and is fine.\n",
      "🔹 Logistic Regression Prediction: Medium\n",
      "🔹 SVM Prediction: Medium\n",
      "🔹 Random Forest Prediction: Medium\n",
      "\n",
      "Text: Poachers are spotted near a protected area, hunting endangered species in broad daylight\n",
      "🔹 Logistic Regression Prediction: Medium\n",
      "🔹 SVM Prediction: Medium\n",
      "🔹 Random Forest Prediction: Medium\n",
      "\n",
      "Text: An illegal logging operation that devastates large sections of the forest, destroying habitats and causing irreversible damage\n",
      "🔹 Logistic Regression Prediction: Medium\n",
      "🔹 SVM Prediction: High\n",
      "🔹 Random Forest Prediction: Medium\n",
      "\n",
      "Text: A camper found dead after lethal bear attack near campfire\n",
      "🔹 Logistic Regression Prediction: Medium\n",
      "🔹 SVM Prediction: Medium\n",
      "🔹 Random Forest Prediction: Medium\n",
      "\n",
      "Text: A minor puddle forms on a hiking path after light rain, causing a slight inconvenience but no hazard\n",
      "🔹 Logistic Regression Prediction: Low\n",
      "🔹 SVM Prediction: Low\n",
      "🔹 Random Forest Prediction: Low\n"
     ]
    }
   ],
   "source": [
    "logreg_model = joblib.load('models/logreg_model.pkl')\n",
    "svm_model = joblib.load('models/svm_model.pkl')\n",
    "rf_model = joblib.load('models/rf_model.pkl')\n",
    "\n",
    "vectorizer = joblib.load('models/vectorizer.pkl')\n",
    "\n",
    "label_encoder = joblib.load('models/label_encoder.pkl')\n",
    "\n",
    "def predict_priority(text):\n",
    "    \"\"\"Preprocess text and predict priority using all models.\"\"\"\n",
    "    \n",
    "    text_vec = vectorizer.transform([text])\n",
    "\n",
    "    logreg_pred = logreg_model.predict(text_vec)[0]\n",
    "    svm_pred = svm_model.predict(text_vec)[0]\n",
    "    rf_pred = rf_model.predict(text_vec)[0]\n",
    "\n",
    "    logreg_priority = label_encoder.inverse_transform([logreg_pred])[0]\n",
    "    svm_priority = label_encoder.inverse_transform([svm_pred])[0]\n",
    "    rf_priority = label_encoder.inverse_transform([rf_pred])[0]\n",
    "\n",
    "    return logreg_priority, svm_priority, rf_priority\n",
    "\n",
    "new_texts = [\n",
    "    \"A massive wildfire is approaching a nearby village, causing panic.\",\n",
    "    \"A group of armed poachers was seen near the protected tiger reserve.\",\n",
    "    \"A rare medicinal plant species is being stolen from the forest.\",\n",
    "    \"A tourist was injured while hiking and is fine.\",\n",
    "    \"Poachers are spotted near a protected area, hunting endangered species in broad daylight\",\n",
    "    \"An illegal logging operation that devastates large sections of the forest, destroying habitats and causing irreversible damage\",\n",
    "    \"A camper found dead after lethal bear attack near campfire\",\n",
    "    \"A minor puddle forms on a hiking path after light rain, causing a slight inconvenience but no hazard\"\n",
    "]\n",
    "\n",
    "for text in new_texts:\n",
    "    logreg_pred, svm_pred, rf_pred = predict_priority(text)\n",
    "    \n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"🔹 Logistic Regression Prediction: {logreg_pred}\")\n",
    "    print(f\"🔹 SVM Prediction: {svm_pred}\")\n",
    "    print(f\"🔹 Random Forest Prediction: {rf_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority\n",
      "Medium    40.625\n",
      "High      30.000\n",
      "Low       29.375\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./trial.csv')\n",
    "print(df['Priority'].value_counts(normalize=True) * 100)  # Check class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Class Weights: {0: 1.1111111111111112, 1: 1.1347517730496455, 2: 0.8205128205128205}\n",
      "Logistic Regression Accuracy: 68.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.94      0.75      0.83        20\n",
      "         Low       0.60      0.67      0.63        18\n",
      "      Medium       0.61      0.65      0.63        26\n",
      "\n",
      "    accuracy                           0.69        64\n",
      "   macro avg       0.71      0.69      0.70        64\n",
      "weighted avg       0.71      0.69      0.69        64\n",
      "\n",
      "SVM Accuracy: 62.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.87      0.65      0.74        20\n",
      "         Low       0.57      0.72      0.63        18\n",
      "      Medium       0.54      0.54      0.54        26\n",
      "\n",
      "    accuracy                           0.62        64\n",
      "   macro avg       0.66      0.64      0.64        64\n",
      "weighted avg       0.65      0.62      0.63        64\n",
      "\n",
      "Random Forest Accuracy: 60.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.87      0.65      0.74        20\n",
      "         Low       0.56      0.50      0.53        18\n",
      "      Medium       0.52      0.65      0.58        26\n",
      "\n",
      "    accuracy                           0.61        64\n",
      "   macro avg       0.65      0.60      0.62        64\n",
      "weighted avg       0.64      0.61      0.62        64\n",
      "\n",
      "Low Risk Prediction: {'Logistic Regression Prediction': 'Low', 'SVM Prediction': 'Low', 'Random Forest Prediction': 'Low'}\n",
      "Medium Risk Prediction: {'Logistic Regression Prediction': 'Medium', 'SVM Prediction': 'Medium', 'Random Forest Prediction': 'Medium'}\n",
      "High Risk Prediction: {'Logistic Regression Prediction': 'High', 'SVM Prediction': 'High', 'Random Forest Prediction': 'High'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./trial.csv')\n",
    "X = df['Description']  \n",
    "y = df['Priority']  \n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=41, shuffle=True)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Save vectorizer & label encoder\n",
    "joblib.dump(vectorizer, 'models/vectorizer_with_weights.pkl')\n",
    "joblib.dump(label_encoder, 'models/label_encoder_with_weights.pkl')\n",
    "\n",
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"Computed Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Logistic Regression with Class Weights\n",
    "logistic_model = LogisticRegression(class_weight=class_weight_dict, max_iter=500, solver='liblinear')\n",
    "logistic_model.fit(X_train_vec, y_train)\n",
    "joblib.dump(logistic_model, 'models/logreg_model_with_weights.pkl')\n",
    "\n",
    "# SVM with Class Weights\n",
    "svm_model = SVC(class_weight=class_weight_dict, kernel='linear')\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "joblib.dump(svm_model, 'models/svm_model_with_weights.pkl')\n",
    "\n",
    "# Random Forest with Class Weights\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=200, max_depth=20, random_state=41)\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "joblib.dump(rf_model, 'models/rf_model_with_weights.pkl')\n",
    "\n",
    "# Predictions\n",
    "y_pred_logistic = logistic_model.predict(X_test_vec)\n",
    "y_pred_svm = svm_model.predict(X_test_vec)\n",
    "y_pred_rf = rf_model.predict(X_test_vec)\n",
    "\n",
    "# Accuracy and Reports\n",
    "accuracy_log = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred_logistic, target_names=label_encoder.classes_))\n",
    "\n",
    "print(f\"SVM Accuracy: {accuracy_svm * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n",
    "\n",
    "# Inference Code\n",
    "def predict_priority(description):\n",
    "    vectorizer = joblib.load('models/vectorizer_with_weights.pkl')\n",
    "    label_encoder = joblib.load('models/label_encoder_with_weights.pkl')\n",
    "    logistic_model = joblib.load('models/logreg_model_with_weights.pkl')\n",
    "    svm_model = joblib.load('models/svm_model_with_weights.pkl')\n",
    "    rf_model = joblib.load('models/rf_model_with_weights.pkl')\n",
    "    \n",
    "    description_vec = vectorizer.transform([description])\n",
    "    \n",
    "    pred_log = logistic_model.predict(description_vec)[0]\n",
    "    pred_svm = svm_model.predict(description_vec)[0]\n",
    "    pred_rf = rf_model.predict(description_vec)[0]\n",
    "    \n",
    "    log_label = label_encoder.inverse_transform([pred_log])[0]\n",
    "    svm_label = label_encoder.inverse_transform([pred_svm])[0]\n",
    "    rf_label = label_encoder.inverse_transform([pred_rf])[0]\n",
    "    \n",
    "    return {\n",
    "        \"Logistic Regression Prediction\": log_label,\n",
    "        \"SVM Prediction\": svm_label,\n",
    "        \"Random Forest Prediction\": rf_label\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "low_risk = \"A small fallen tree branch is blocking part of the trail.\"\n",
    "medium_risk = \"A group of hikers reported seeing a bear near the campsite.\"\n",
    "high_risk = \"A large wildfire spreading rapidly near the forest reserve.\"\n",
    "\n",
    "print(\"Low Risk Prediction:\", predict_priority(low_risk))\n",
    "print(\"Medium Risk Prediction:\", predict_priority(medium_risk))\n",
    "print(\"High Risk Prediction:\", predict_priority(high_risk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Over Sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
